apiVersion: batch/v1
kind: Job
metadata:
  generateName: ${USER}-job-generate-${JOB_SUFFIX}
  labels:
    eidf/user: ${USER}
    kueue.x-k8s.io/queue-name: ${KUBE_USER_QUEUE}
    kueue.x-k8s.io/priority-class: batch-workload-priority
spec:
  completions: 1
  parallelism: 1
  completionMode: Indexed
  backoffLimit: 2147483647
  activeDeadlineSeconds: 864000
  template:
    metadata:
      labels:
        eidf/user: ${USER}
    spec:
      restartPolicy: OnFailure
      # Replace nodeSelector with affinity to allow multiple GPU types.
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
              - matchExpressions:
                  - key: nvidia.com/gpu.product
                    operator: In
                    values:
                      - NVIDIA-A100-SXM4-80GB
      # Add tolerations to allow scheduling on nodes with specific taints.
      tolerations:
        - key: "eidf107"
          operator: "Equal"
          value: "True"
          effect: "NoSchedule"
      containers:
        - name: crack-in-the-bark
          image: linjunhua3/crack-bark:latest  # Ensure CUDA version matches host drivers
          workingDir: "/workspace/kubernets"
          env:
            - name: PYTHONPATH
              value: "/workspace/kubernets"
          command: ["/bin/bash", "-c"]
          args:
            - |
              echo "Setting up environment..."
              git clone "https://github.com/JunhuaL/crack-in-the-bark.git" .
              git checkout feature/port-over
              
              # Download pretrained models
              echo "Downloading pretrained models..."
              curl -o 512x512_diffusion.pt "https://openaipublic.blob.core.windows.net/diffusion/jul-2021/512x512_diffusion.pt"
              
              echo "Starting generation..."
              export PYTHONPATH=$PYTHONPATH:/workspace/kubernets

              python generate_data.py --run_name="imagenet_data" \
                                      --model_id="512x512_diffusion" \
                                      --gen_with_wm \
                                      --w_channel=2 \
                                      --w_pattern="ring" \
                                      --device="cuda" \
              
              scp -r logs /workspace/data_storage/
              exit_status=$?
              echo "Training finished with exit status $exit_status"
          resources:
            limits:
              nvidia.com/gpu: "1"
              cpu: "4"
              memory: "32Gi"
          volumeMounts:
            - name: datastorage
              mountPath: /workspace/data_storage
      volumes:
        - name: datastorage
          persistentVolumeClaim:
            claimName: ${USER}-ws1